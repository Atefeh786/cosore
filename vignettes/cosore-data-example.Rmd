---
title: "Working with COSORE data"
author: "Ben Bond-Lamberty"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
%\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  ---
  
  ```{r setup, include = FALSE}
knitr::opts_chunk$set(
echo = TRUE,
collapse = TRUE,
comment = "#>"
)
```

# Introduction

Soil respiration--the flux of CO2 from the soil surface to the atmosphere--has been measured by continuous (typically hourly) measurement systems in many places over the last 25 years. The goal of the COSORE database is to collect many of these data into a single open community resource to support data synthesis and transparency. 

The database is distributed as a zip file, available through GitHub releases [here](https://github.com/bpbond/cosore/releases). When you download and extract the file, there's a README, the data in two separate formats, and a number of other files (including a version of this vignette).

But how do we work with this database, exactly? Let's start by loading it into R:

```r
cosore <- readRDS("cosore_data.RDS")
```

```{r, echo=FALSE}
# For the vignette, we just read from the drake cache, not use readRDS as above
try(cosore <- drake::readd("all"))

# I don't understand why, but when devtools::check runs this at its
# 'checking re-building of vignette outputs' step, it will load the
# cosore data structure but not the `data` elements of each dataset
# list, throwing an error when things bomb below. Huh?!?
# Check for this and create a fake database if necessary
data_loaded <- is.data.frame(cosore$d20190415_VARNER$data)

if(!data_loaded) {   # no database available; create a fake one
  cosore <- list(
    d20190415_VARNER = list(
      description = data.frame(CSR_DATASET = "d20190415_VARNER",
                               CSR_SITE_NAME = "1",
                               CSR_IGBP = "Deciduous broadleaf forest",
                               CSR_LONGITUDE = 1,
                               CSR_LATITUDE = 1),
      data = data.frame(CSR_TIMESTAMP = lubridate::ymd_hm("2019-06-05 07:12"),
                        CSR_FLUX = 1,
                        CSR_PORT = 1,
                        CSR_T5 = 1))
  )
}
```

This database is comprised of a collection of datasets, each converted to a standard format and units. A dataset is one or more files of continuous (automated) soil respiration data, with accompanying metadata, with all measurements taken at a single site and with constant treatment assignments.

In practice, the `COSORE` database is structured as a two-level nested list of data frames:

```
cosore
|- dataset 1
|   |- description table (a data.frame)
|   |- contributors table (same...)
|   |- ports table
|   |- columns table
|   |- ancillary table
|   |- data table
|   |- diagnostics table
|- dataset 2
|   |- description table
|   |- contributors table
|   |- ports table
|   |- columns table
|   |- ancillary table
|   |- data table
|   |- diagnostics table
|- dataset 3
|   |- etc.
```

For most analyses we want to extract one or more of these pieces and combine them--for example, to get a single table of contributors. There are [various](https://cran.r-project.org/package=purrr) [packages](https://cran.r-project.org/package=rlist) for dealing with nested lists, but we can also write our own short extractor function:

```{r extractor, echo=TRUE}
csr_table <- function(cosore, table_name) {
  
  extract <- function(x, table_name) {
    if(is.null(x[[table_name]])) { return(NULL) }
    # Add an identifier field so we can track things as tables get combined
    x[[table_name]]$CSR_DATASET <- x$description$CSR_DATASET
    x[[table_name]]
  }
  
  dplyr::bind_rows(lapply(cosore, extract, table_name = table_name))
}
```

With this in place, we extract a combined `description` table for the entire database and take a look at it:

```{r description-table}
desc <- csr_table(cosore, "description")
tibble::glimpse(desc)
```

Lots of information! (Note much of this is summarized in the `Report-all.html` file included with the data download.) Let's start with a single dataset and work our way up to multi-data analyses.

# Exploring a single dataset

To begin, we pick a single dataset (`d20190415_VARNER`), get some information about it, and plot it.

```{r desc-varner}
varner <- cosore$d20190415_VARNER
tibble::glimpse(varner$description)
```

The `description` table gives the basic information about this dataset:
where it was measured, the time zone that the `data` timestamps are in, 
instrument used, and citation and acknowledgment information.

```{r sr-varner}
sr <- varner$data
nrow(sr)
summary(sr)
```

This dataset has `r nrow(sr)` observations; extends from April 2003 to December 2006; and soil respiration was measured on eight ports, along with air and 5 cm soil temperature. Visualizing it:

```{r visualize-varner}
library(ggplot2)
ggplot(sr, aes(CSR_TIMESTAMP, CSR_FLUX, color = CSR_PORT)) +
  geom_point(size = 0.5) + ggtitle("Flux over time")

library(lubridate, warn.conflicts = FALSE)
ggplot(sr, aes(CSR_T5, CSR_FLUX)) + 
  facet_wrap(~month(CSR_TIMESTAMP), scales = "free") +
  geom_point(size = 0.5, alpha = 0.5) +
  ggtitle("5 cm soil temp vs. flux, by month")
```

Did these eight different ports (chambers) represent different treatments?
We might want to exclude treatment collars, or color them differently 
in the plots above.

```{r ports-varner}
varner$ports
```

From this we see that the only `Port` entry is zero, with `Treatment` of "None", i.e. all ports/collars had the same treatment, and there _wasn't_ any treatment. Also, the collars were `r varner$ports$CSR_AREA` cm2.

Finally, we can use the `description` table information to get a full citation:

```{r pub-varner}
doi <- varner$description$CSR_PRIMARY_PUB
print(doi)
library(rcrossref)
try(cr_cn(dois = doi, format = "text"))
```

# Selecting and combining multiple datasets

Time for something more ambitious.

Let's examine how soil respiration varies over the course of the day in temperate deciduous forests.

```{r dbf-map}
# The dplyr package is really good for this kind of filter-and-join thing,
# but all the steps below can be replicated with base R commands too of course
library(dplyr, warn.conflicts = FALSE)
desc %>%   # our combined 'description' table, from above
  filter(CSR_IGBP == "Deciduous broadleaf forest") ->
  tdf

# Make a map of these datasets
library(sp)
library(leaflet)
map <- data.frame(lon = tdf$CSR_LONGITUDE, lat = tdf$CSR_LATITUDE)
coordinates(map) <- ~lon + lat
leaflet(map) %>% 
  addMarkers() %>% 
  addTiles()
```

There are `r nrow(tdf)` datasets here; let's extract them.

```{r dbf-data}
cosore_tdf <- cosore[tdf$CSR_DATASET]
tdf_dat <- csr_table(cosore_tdf, "data")
tdf_dat %>% 
  mutate(Yday = yday(CSR_TIMESTAMP), Year = year(CSR_TIMESTAMP)) %>% 
  ggplot(aes(Yday, CSR_FLUX, group = CSR_PORT, color = Year)) + 
  geom_point(size = 0.5) + 
  facet_wrap(~CSR_DATASET, scales = "free") +
  scale_color_continuous("Year") +
  coord_cartesian(ylim = c(0, 20))
```

The original question we were interested in was how respiration varies over the course of the day. (Note for simplicity below we're assuming that data timestamps are in local time, but that might not be true, e.g. if an instrument is set to UTC; see the `description` table.)

```{r dbf-day}
tdf_dat %>% 
  # join two tables together
  left_join(select(tdf, CSR_DATASET, CSR_SITE_NAME, CSR_LATITUDE), by = "CSR_DATASET") %>% 
  # add some new fields
  mutate(Hour = hour(CSR_TIMESTAMP),
         Month = month(CSR_TIMESTAMP), 
         Year = year(CSR_TIMESTAMP)) %>% 
  # for each month, compute mean flux for each hour of the day
  group_by(CSR_DATASET, CSR_LATITUDE, Year, Month, Hour) %>% 
  summarise(CSR_FLUX = mean(CSR_FLUX)) %>% 
  
  ggplot(aes(Hour, CSR_FLUX, color = CSR_LATITUDE)) + 
  geom_point(size = 0.5) + facet_wrap(~Month) +
  ggtitle("Flux by hour of day and month of year")
```

Plot the data in a different way...TODO.

# Other tables and data

This vignette has mostly focused on the `description` and `data` tables, and briefly mentioned `ports`. Others include:

* the `contributors` table: dataset contributors. The first person listed should be considered the primary point of contact.
* `ancillary`: ancillary site-level data such as leaf area index, net primary production, soil texture, etc. All optional.

Two additional tables that provide information about the processing of raw data into standardized COSORE datasets:

* `columns`: describes how columns in the original dataset (as contributed) were mapped to the COSORE standard fields, including any unit changes or transormations.
* `diagnostics`: metadata about the data ingestion process: rows and columns removed, errors, etc.

These can all be extracted using a method like the `csr_table()` function above.

# Feedback and data contributions

Feedback is welcome on any aspects of the database design, strengths, limitations, formats, documentation...please [open a GitHub issue](https://github.com/bpbond/cosore/issues/new) or email; see the README.
