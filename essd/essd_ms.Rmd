---
title: 'COSORE: a community database for continuous soil respiration and other chamber
  fluxes'
output:
  html_document: default
  word_document: default
date: "`r format(Sys.time(), '%d %B %Y')`"
---

This document is the core of the planned ESSD manuscript: summarizing the database, giving stats, describing functions, etc. Most of the introductory text with citations will be in the Google Doc.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(cosore)
library(dplyr)
library(lubridate)
library(readr)
library(tidyr)
library(covr)
library(magrittr)
library(ggplot2)
theme_set(theme_bw())

db <- csr_database()
db_records <- round(sum(db$CSR_RECORDS, na.rm = TRUE) / 1e6, 2)
db_years <- max(year(db$CSR_DATE_END), na.rm = TRUE) - min(year(db$CSR_DATE_BEGIN), na.rm = TRUE) + 1
db_fields <- csr_metadata()
db_vers <- packageVersion("cosore")
```

```{r authors, results='asis'}
# Generate a list of potential authors from the database
csr_table("contributors") %>% 
  left_join(select(db, CSR_DATASET, CSR_RECORDS), by = "CSR_DATASET") %>% 
  filter(CSR_RECORDS > 0) %>%  # only authors who contribute data
  group_by(CSR_DATASET) %>% 
  mutate(`Author?` = "No", 
         `Institution and address` = "") %>% 
  select(CSR_DATASET, CSR_FAMILY_NAME, CSR_FIRST_NAME, `Author?`,
         CSR_EMAIL, CSR_ORCID, `Institution and address`) %T>% 
  write_csv("authors_from_database.csv", na = "") %>% 
  group_by(CSR_DATASET) %>% 
  filter(CSR_FAMILY_NAME == first(CSR_FAMILY_NAME)) %>% 
  pull(CSR_EMAIL) %>% 
  unique() %>% 
  write_lines("authors_contact.csv")

# Read the edited list of potential authors, from the Google Sheet, and generate the
# author list and contact list
read_csv("authors_from_google_sheets.csv", skip = 1, col_types = "cccccccc") %>% 
  rename(institution = `Institution, city, postal code, country`) %>% 
  mutate(institution = if_else(is.na(institution), 
                               paste("<b>TODO missing:</b>", CSR_DATASET, CSR_FAMILY_NAME), institution)) %>% 
  filter(`Author?` %in% c("Yes", "yes", "Y")) %>%
  distinct(CSR_FAMILY_NAME, CSR_FIRST_NAME, CSR_EMAIL, institution, .keep_all = TRUE) %T>% 
  write_csv("author_final.csv") ->
  authors

# First four authors are fixed; after that it's alphabetical
authors <- bind_rows(authors[1:5,],
                     arrange(authors[-1:-5,], CSR_FAMILY_NAME, CSR_FIRST_NAME))
a_names <- paste(authors$CSR_FIRST_NAME, authors$CSR_FAMILY_NAME)
a_inst_numbers <- as.character(as.numeric(factor(authors$institution, 
                                                 levels = unique(authors$institution))))
institution_list <- authors$institution[!duplicated(a_inst_numbers)]

# Any duplicate names at this point mean multiple institutions; concatenate
dupes <- which(duplicated(a_names))
if(length(dupes)) {
  a_inst_numbers[dupes - 1] <- paste(a_inst_numbers[dupes - 1], a_inst_numbers[dupes], sep = ",")
  a_inst_numbers <- a_inst_numbers[-dupes]
  a_names <- a_names[-dupes]
}

cat(paste0(a_names, "<sup>", a_inst_numbers, "</sup>"), sep = ", ")
cat("<ol>\n") # ordered HTML list
cat(paste0("\t<li>", institution_list, "</li>"), sep = "\n")
cat("</ol>\n")
```


COSORE is designed to be a relatively lightweight database: as simple as possible, but not simpler. 
It is targeted at continuous soil respiration flux data--i.e., those measured by automated systems on a e.g. half hourly basis--but its design accommodates survey-style R~S~ fluxes, methane fluxes, and chamber measurements of net ecosystem exchange as well, paralleling the recent SIdB database (TODO). 
Its development started in April 2019, and as of this writing (`r Sys.Date()`) the COSORE version number is `r db_vers`. 
The database currently has `r nrow(db)` contributed datasets with a total of `r db_records` million flux observations across `r db_years` years and five continents (Table X, Figures X and Y). 

_Database and dataset structure_

The database is structured as a collection of independent contributed _datasets_, all of which have been standardized to a common structure, units, etc. 
Each dataset is given a reference name that links its constituent tables, provides a point of reference in reports, and is used when calling the R package accessor functions (see below).

Each constituent dataset normally has a series of separate data tables that are linked by keys.
These tables include:

* _description_ (**Table 2**) describing site and dataset characteristics;
* _contributors_ (**Table 3**) listing individuals who contributed to the measurement, analysis,
curation, and/or submission of the dataset; 
* _ports_ (**Table 4**) which gives the different _ports_ (generally equivalent to separate measurement chambers) in use, and what each is measuring: flux, species, and treatment, as well as characteristics of the measurement collar;
* _data_ (**Table 5**), the central table of the dataset, which records flux observations;
* _ancillary_ (**Table 6**) summarizing site-level ancillary measurements;
* _columns_ (**Table 7**), mapping raw data columns to standard COSORE columns, providing a record for reproducibility; and
* _diagnostics_ (**Table 8**), which provides statistics on the data import process: errors, columns and rows dropped, etc.

The common key linking these dataset tables is the CSR_DATASET field, which records the unique name assigned to the dataset. In addition, a CSR_PORT key field links the _ports_ and _data_ tables. These links make it straightforward to extract datasets that have measured particular fluxes in
certain ecosystem types, or isolate only non-treatment (control) chamber fluxes, for example.

_Versioning and archiving_

COSORE uses semantic versioning (https://semver.org/), meaning that its version numbers
generally follow an "x.y.z" format, where _x_ is the major version number (changing only when there are major changes to the database or package structure and/or function, in a manner that may break existing scripts using the data); _y_ is the minor version number (typically changing with significant data updates); and _z_ the patch number (bug fixes, documentation upgrades, or other changes that are completely backwards compatible).
Following each official (major) release a DOI will be issued and the data archived by Zenodo (https://zenodo.org/).
All changes to the data or codebase are immediately available through the GitHub repository, but only official releases will be issued a DOI.

_Data license and citation_

The database license is CC-BY-4 (https://creativecommons.org/licenses/by/4.0/); see the "LICENSE" file in the repository.
This is identical to that used by e.g. FLUXNET Tier 1. 
In general, this license provides that users may copy and redistribute the database and R package code in any medium or format, adapting and building upon them for any scientific or commercial purpose, as long as appropriate credit is given.
We request that users cite this database definition paper, and strongly encourage them to (i) cite all constituent dataset primary publications, and (ii) involve data contributors as co-authors when possible.

Papers or other research products using COSORE should cite this publication. 
In addition, users should also reference the specific version of the dataset they used (e.g. `r db_vers`), access date, and ideally the specific Git commit number. 
This provides full reproducibility of any analyses.
As noted above, we encourage data users to cite the primary publication for each dataset
they use in analyses as well.

**Data access and use**

COSORE data releases are currently available via the GitHub "Releases" page at https://github.com/bpbond/cosore/releases, although we anticipate that institutional repositories such as ESS-DIVE (https://ess-dive.lbl.gov/) may host releases at some point in the future.
Downloads via this page are flat-file CSV (comma-separated value), and readable by any modern computing system. 
Missing values are encoded by a blank (i.e. two successive commas in the CSV format).
A release download is fully self-contained, with full data, metadata, and documentation; a file manifest; a copy of the data license; an introductory vignette; a summary report on the entire database; and an explanatory README with links to this publication.

```{r dbsize, include=FALSE, cache=TRUE}
db_memsize <- sum(sapply(db$CSR_DATASET, function(x) object.size(csr_dataset(x)$data))) / 1e6
db_disksize <- system2("git", 
                       args = c("count-objects", "-vH"), 
                       stdout = TRUE)
db_disksize <- db_disksize[grepl("size:",db_disksize)]
db_disksize <- gsub("size: ", "", db_disksize)
```

An alternative way to access COSORE data is to install and use the _cosore_ R (TODO CITATION) package.
This provides a robust framework, including dedicated access functions, dataset and database report generation, and QA/QC (see below).
Because currently the flux data are included in the repository itself, the latter is quite large (compared to most Git repositories) to download, ~`r db_disksize`. 
(Note that the data are stored in R's compressed RDS file format; when loaded into memory, the entire database is significantly larger, ~`r round(db_memsize, 0)` MB.) 
It thus cannot easily be hosted on CRAN (the Comprehensive R Archive Network), the canonical source for R packages. Installing directly from GitHub is however straightforward using the _devtools_ or _remotes_ packages:

```
devtools::install_github("bpbond/cosore")
library(cosore)
```

A specific release number may also be installed:

```
devtools::install_github("bpbond/cosore@v0.4")
```

Four primary user-facing functions are available:

* *csr_database()* summarizes the entire database in a single convenient data frame, with one row per dataset, and is intended as a high-level overview. It returns a selection of variables summarized in **Tables 2-8** below, including dataset name, longitude, latitude, elevation, IGBP code, number of records, dates, and variables measured.
* *csr_dataset()* returns a single dataset: an R list structure, each element of which is a table (_description_, _contributors_, etc., as described above). 
* *csr_table()* collects, into a single data frame, one of the tables of the database, for any or all datasets.
* *csr_metadata()* provides metadata information about all fields in all tables.

Two additional reporting functions may also be useful to users:

* *csr_report_database()* generates an HTML report on the entire database: number of datasets, locations, number of observations, distribution of flux values, etc.
* *csr_report_dataset()* generates an HTML report on a single dataset, including tabular and graphical summaries of location, flux data, diagnostics, etc.

Finally, a number of functions are targeted at developers, and include functionality to ingest contributed data, standardize data, and prepare a new release. See the package documentation for more details on these.

_Documentation_

The primary documentation for the COSORE database is this paper.
Both the flat-file releases and `cosore` R package include extensive documentation, including an in-depth vignette included both in the package and online (LINK TODO).
The R package includes documentation available via R's standard help system.

_Data quality and testing_

When contributed data are imported into COSORE, the package code performs a number of quality assurance checks. These include:

* Timestamp errors, for example illegal dates and times for the specified time zone
* Bad email addresses or ORCID identifiers
* Records with no flux value
* Records for which the analyzer recorded an error condition

```{r errors, cache=TRUE}
# Calculate what percent of observations are removed across all datasets
csr_table("diagnostics", quiet = TRUE) %>% 
  group_by(CSR_DATASET, CSR_RECORDS) %>% 
  summarise(removed = CSR_RECORDS_REMOVED_NA + CSR_RECORDS_REMOVED_ERR + CSR_RECORDS_REMOVED_TIMESTAMP) %>% 
  ungroup() %>% 
  mutate(removed_pct = removed / (removed + CSR_RECORDS) * 100) %>% 
  pull(removed_pct) -> errs
```

Any errors flagged or records removed during this process are summarized in the _diagnostics_ table that is part of each dataset (**Table 7** below). Across all contributed datasets, a median of `r round(median(errs), 1)`% of raw observations were removed for one of these reasons.

```{r coverage, cache=TRUE}
# We exclude parse-others.R from the coverage calculation, because it's all
# temporary code for handling specific raw datasets, and will eventually go away
package_coverage(line_exclusions = list("R/parse-others.R")) %>% 
  percent_coverage() ->
  csr_cov
```

The _cosore_ R package also has a wide variety of unit tests (CITATION TODO) that test code functionality, typically via assertions about function behavior, but also by verifying behavior of those functions when importing test datasets (of different formats and with a variety of errors, for example). In total these tests cover `r round(csr_cov, 1)`% of the codebase.


# Tables

**Table 1.** Summary of COSORE v. `r db_vers` datasets with deposited data, by International Geosphere-Biosphere Programme land cover classification (CITATION TODO). Columns include number of datasets, total number of records (flux observations), and dates of first and last records.

```{r table_igbp}
smrise <- function(x) {
  x %>% 
    summarise(Datasets = n(),
              Records = format(sum(CSR_RECORDS, na.rm = TRUE), big.mark = ","),
              `First record` = min(CSR_DATE_BEGIN, na.rm = TRUE),
              `Last record` = max(CSR_DATE_END, na.rm = TRUE)) 
}
db %>% 
  filter(CSR_RECORDS > 0) %>% 
  select(`IGBP class` = CSR_IGBP, CSR_RECORDS, CSR_DATE_BEGIN, CSR_DATE_END) %>% 
  group_by(`IGBP class`) %>% 
  smrise() %>% 
  bind_rows(bind_cols(tibble(`IGBP class` = "(Total)"), smrise(db))) %>% 
  knitr::kable(format = "markdown", align = c("l", "r", "r", "r", "r"))
```

**Table 2.** Individual datasets in COSORE have a number of sub-tables. The first of these is the _description_ table, the fields of which are summarized below. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_description}
options(knitr.kable.NA = "")
make_table <- function(db_fields, table) {
  db_fields %>% 
    rename(`Field name` = Field_name) %>% 
    filter(Table_name == table) %>%
    mutate(Required = if_else(Required, "*", "")) %>% 
    select(-Table_name) %>% 
    kableExtra::kable(format = "markdown")
}
make_table(db_fields, "description")
```

**Table 3.** Summary of COSORE's _contributors_ table, which provides information on the researchers who measured and contributed each dataset. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required. Note that although none of the columns in this table are marked as required, at least one contributor (with filled-in name and email) is required for each dataset.

```{r table_contributors}
make_table(db_fields, "contributors")
```

**Table 4.** Summary of COSORE's _ports_ table, which provides information on the various multiplexed chambers that are frequently connected to a single measurement analyzer. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_ports}
make_table(db_fields, "ports")
```

**Table 5.** Summary of COSORE's _data_ table, which holds the actual flux observations and accompanying time-stamped data. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_data}
make_table(db_fields, "data")
```

**Table 6.** Summary of COSORE's _ancillary_ table, which includes optional information, typically ecosystem-level soil information, carbon fluxes, and climate normals. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_ancillary}
db_fields %>% 
  #  filter(Field_name %in%  c("Variable", "Value")) %>% 
  make_table("ancillary")
```

**Table 7.** Summary of COSORE's _columns_ table, which maps raw dataset columns to standardized COSORE columns. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required. We expect that this table will be dropped at some point in the future when COSORE requires structurally compliant data submissions (i.e. contributors will be required to format their data to match COSORE structure before submission).

```{r table_columns}
make_table(db_fields, "columns")
```

**Table 8.** Summary of COSORE's _diagnostics_ table, which is populated automatically when parsing and importing non-COSORE data. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_diagnostics}
make_table(db_fields, "diagnostics")
```

**Figure 1.** World satellite image with COSORE data submission sites shown as blue diamonds. Areas with multiple submissions are shown as darker.

```{r worldmap, message = FALSE, echo = FALSE, warning = FALSE}
library(ggmap)
library(scales)

bbox <- make_bbox(lon = c(-160, 150), lat = c(-50, 70)) # make a coordinate box 
map <- get_map(location = bbox, source = "stamen", maptype = "terrain") # load map from online

p <- ggmap(map) + 
  geom_point(data = db, aes(x = CSR_LONGITUDE, y = CSR_LATITUDE, size = CSR_RECORDS), 
             alpha = 0.6, color = "blue4", shape = 18) + 
  labs(x = "Longitude", y = "Latitude") +
  scale_size_continuous("", labels = comma) +
  scale_fill_manual(name = "", values = c("COSORE Submission Site" = "#FC4E07")) +
  scale_shape_manual(values = 18) + theme(legend.position = "bottom")
print(p)
ggsave("figures/figure1-map.png")
```

**Figure 2.** Climate space.

```{r mat-map}
#source("mat-map.R")
# Load libraries
library(raster)
library(sp)
library(RColorBrewer)

# Download worldclim data for precip and tmean, store in essd/ folder
if(!file.exists("wc10/prec_10m_bil.zip")) {
  precip <- getData("worldclim", path = "essd/", var = "prec", res = 10)
  tmean <- getData("worldclim", path = "essd/", var = "tmean", res = 10)
}

# Pull out cosore dataset latitudes and longitudes
db %>%
  dplyr::select(CSR_LONGITUDE, CSR_LATITUDE) -> cosore_coords

# Extract cosore location data from worldclim data for precip...
raster::extract(precip, cosore_coords) -> precip_coords
apply(precip_coords, 1, mean) -> map_cosore
cbind(cosore_coords, map_cosore) -> map_coords

# ...and tmean
raster::extract(tmean, cosore_coords) -> tmean_vals
apply(tmean_vals, 1, mean) -> mat_cosore
cbind(map_coords, mat_cosore) -> mat_coords

left_join(map_coords, mat_coords) %>%
  # Temp data is stored in degC * 10, so we need to divide to get back to degC
  mutate(mat_cosore = mat_cosore / 10) -> cosore_points

# Extract global climate space data
raster::as.data.frame(precip, xy = TRUE) %>%
  drop_na() -> precip_global

# Calculate annual mean for precip...
precip_global %>%
  dplyr::select(-x, -y) %>%
  apply(1, mean) -> map_global

raster::as.data.frame(tmean, xy = TRUE) %>%
  drop_na() -> tmean_global

# ...and tmean
tmean_global %>%
  dplyr::select(-x, -y) %>%
  apply(1, mean) -> mat_global

# Create tibble with corresponding coordinates
tibble(x = tmean_global$x, y = tmean_global$y, mat = as.vector(mat_global)) -> mat
tibble(x = precip_global$x, y = precip_global$y, map = as.vector(map_global)) -> map

left_join(map, mat, by = c("x", "y")) %>%
  # Temp data is stored in degC * 10, so we need to divide to get back to degC
  mutate(mat = mat/10) -> map_mat_global

p <- ggplot() +
  geom_hex(data = map_mat_global,
             aes(x = mat, y = map), bins = 100) +
  scale_fill_distiller(palette = "YlGnBu", name = "Grid cells") +
  geom_point(data = cosore_points, aes(x = mat_cosore, y = map_cosore),
             color = "darkorange", shape = 4, size = 1.5, na.rm = TRUE) +
  theme_minimal() +
  labs(x = "MAT (°C)", y = "MAP (mm)")
ggsave("figures/figure2-climate.png")
```

**Figure 3.** Waffle plot of COSORE Coverage by IGBP by year of measurement. Here, one square equals 1,000 datapoints.

```{r flux-density, message = FALSE, echo = FALSE, eval=FALSE}
# devtools::install_github("liamgilbey/ggwaffle")
# library(ggwaffle)

db %>% 
  mutate(Date = date(CSR_DATE_BEGIN), 
         Month = month(CSR_DATE_BEGIN), 
         Year = year(CSR_DATE_BEGIN)) %>% 
  group_by(Year, CSR_IGBP) %>%
  summarise(Date = mean(Date), Records = sum(CSR_RECORDS)) -> 
  avg

p <- ggplot(avg, aes(Year, Records, fill = CSR_IGBP)) + 
  geom_bar(stat = "identity", na.rm = TRUE) + 
  scale_y_continuous(labels = comma)
print(p)
ggsave("figures/figure3-waffle.png")

# waffle plot no of records by IGBP
# ggplot(avg, aes(fill = CSR_IGBP, values = n)) +
#   geom_waffle(color = "white", size = .25, n_rows = 10, flip = TRUE) +
#   facet_wrap(~Year, nrow = 2, strip.position = "bottom") +  coord_equal() +
#   labs(subtitle = "1 block = 1,000 data points",
#        x = "Year",
#        y = "Count") +
#   theme_minimal() +
#   theme(panel.grid = element_blank()) + 
#   theme(axis.text.x = element_blank(),
#         axis.text.y = element_blank(),
#         axis.ticks = element_blank())

#still need to figure out what happens to datapoints under 1000

```

**Figure 4.** Temporal data coverage by latitude.

```{r lat-coverage, message = FALSE, echo = FALSE, eval=FALSE, cache=TRUE}
# Get data density by month of year
datasets <- db$CSR_DATASET
results <- lapply(datasets, function(x) {
  d <- csr_dataset(x)
  if(!is.data.frame(d$data)) return(NULL)
  if(!"CSR_FLUX_CO2" %in% names(d$data)) d$data$CSR_FLUX_CO2 <- NA_real_
  if(!"CSR_FLUX_CH4" %in% names(d$data)) d$data$CSR_FLUX_CH4 <- NA_real_
  d$data %>% 
    mutate(year = year(CSR_TIMESTAMP_BEGIN),
           month = month(CSR_TIMESTAMP_BEGIN)) %>% 
    group_by(year, month) %>% 
    summarise(timestamp = mean(CSR_TIMESTAMP_BEGIN),
              n_co2 = sum(!is.na(CSR_FLUX_CO2)),
              n_ch4 = sum(!is.na(CSR_FLUX_CH4))) %>% 
    mutate(CSR_DATASET = x,
           CSR_LATITUDE = d$description$CSR_LATITUDE)
})
results_lat <- bind_rows(results)

p <- results_lat %>% 
  mutate(Quarter = floor(month / 3),
         Lat_bin = floor(CSR_LATITUDE / 3) * 3) %>%
  group_by(year, Quarter, Lat_bin) %>% 
  summarise(Records = sum(n_co2) / 3,
            timestamp = mean(timestamp)) %>% 
  ggplot(aes(timestamp, Lat_bin, color = Records)) + 
  geom_point(size = 2) + 
  labs(x = "Year", y = "Latitude") +
  scale_color_continuous(labels = comma)
print(p)
ggsave("figures/figure4-latitude.png")
```

**Figure 5.** Temporal data coverage by day of year and hemisphere

```{r doy-counts}
results <- lapply(datasets, function(x) {
  d <- csr_dataset(x)
  if(!is.data.frame(d$data)) return(NULL)
  if(!"CSR_FLUX_CO2" %in% names(d$data)) d$data$CSR_FLUX_CO2 <- NA_real_
  if(!"CSR_FLUX_CH4" %in% names(d$data)) d$data$CSR_FLUX_CH4 <- NA_real_
  d$data %>% 
    mutate(yearday = yday(CSR_TIMESTAMP_BEGIN)) %>% 
    group_by(yearday) %>% 
    summarise(n_co2 = sum(!is.na(CSR_FLUX_CO2)),
              n_ch4 = sum(!is.na(CSR_FLUX_CH4)),
              co2 = mean(CSR_FLUX_CO2, na.rm = TRUE),
              ch4 = mean(CSR_FLUX_CH4, na.rm = TRUE)) %>% 
    mutate(CSR_DATASET = x,
           CSR_LATITUDE = d$description$CSR_LATITUDE)
})
results_doy <- bind_rows(results)


results_doy %>% 
  mutate(Hemi = if_else(CSR_LATITUDE < 0, "Southern hemisphere", "Northern hemisphere")) %>% 
  group_by(Hemi, yearday) %>% 
  summarise(n_ch4 = sum(n_ch4), 
            n_co2 = sum(n_co2)) %>% 
  filter(yearday <= 365) %>% 
  gather(variable, value, n_ch4, n_co2) %>% 
  separate(variable, into = c("junk", "Gas")) %>% 
  mutate(Gas = toupper(Gas)) -> 
  doy_counts

p <- ggplot(data = doy_counts, aes(x = yearday, y = value)) + 
  geom_line() + 
  facet_wrap(~Hemi + Gas, scales = "free") +
  labs(x = "Day of year", y = "Number of observations") +
  scale_y_continuous(labels = comma)
print(p)
ggsave("figures/figure5-doy.png")
```

```{r flux-prep}
results <- lapply(datasets, function(x) {
  d <- csr_dataset(x)
  if(!is.data.frame(d$data)) return(NULL)
  if(!"CSR_FLUX_CO2" %in% names(d$data)) d$data$CSR_FLUX_CO2 <- NA_real_
  if(!"CSR_FLUX_CH4" %in% names(d$data)) d$data$CSR_FLUX_CH4 <- NA_real_
  tibble(CSR_DATASET = d$description$CSR_DATASET,
         IGBP = d$description$CSR_IGBP,
         CSR_FLUX_CO2 = d$data$CSR_FLUX_CO2,
         CSR_FLUX_CH4 = d$data$CSR_FLUX_CH4)
})
results_fluxes <- bind_rows(results)

co2_limits <- c(-1, 15)
ch4_limits <- c(-5, 25)
out_co2 <- filter(results_fluxes, is.finite(CSR_FLUX_CO2), CSR_FLUX_CO2 < min(co2_limits) | CSR_FLUX_CO2 > max(co2_limits))
out_ch4 <- filter(results_fluxes, is.finite(CSR_FLUX_CH4), CSR_FLUX_CH4 < min(ch4_limits) | CSR_FLUX_CH4 > max(ch4_limits))
pct_co2 <- round(nrow(out_co2) / nrow(filter(results_fluxes, is.finite(CSR_FLUX_CO2))) * 100, 1)
pct_ch4 <- round(nrow(out_ch4) / nrow(filter(results_fluxes, is.finite(CSR_FLUX_CH4))) * 100, 1)
```

Figure 6. Distribution of CO2 fluxes in COSORE datasets, by IGBP classification. For visual clarity this figure excludes fluxes <`r min(co2_limits)` and >`r max(co2_limits)` µmol m-2 s-1 (`r nrow(out_co2)` observations, `r pct_co2`% of the data).

```{r flux-co2}

p <- results_fluxes %>% 
  filter(is.finite(CSR_FLUX_CO2), CSR_FLUX_CO2 >= min(co2_limits), CSR_FLUX_CO2 <= max(co2_limits)) %>% 
  ggplot(aes(x = CSR_FLUX_CO2)) + 
  geom_histogram(bins = 30) +
  facet_wrap(~IGBP, scales = "free_y") +
  scale_y_continuous(labels = comma) +
  labs(x = expression(CO[2]~flux~(µmol~m^-2~s^-1)), y = "Number of observations")
print(p)
ggsave("figures/figure6-co2.png")
```

Figure 7. Distribution of CH4 fluxes in COSORE datasets, by IGBP classification. For visual clarity this figure excludes fluxes <`r min(ch4_limits)` and >`r max(ch4_limits)` nmol m-2 s-1 (`r nrow(out_ch4)` observations, `r pct_ch4`% of the data).


```{r, flux-ch4}
p <- results_fluxes %>% 
  filter(is.finite(CSR_FLUX_CH4), CSR_FLUX_CH4 >= min(ch4_limits), CSR_FLUX_CH4 <= max(ch4_limits)) %>% 
  ggplot(aes(x = CSR_FLUX_CH4)) + 
  geom_histogram(bins = 30) +
  facet_wrap(~IGBP, scales = "free") +
  scale_y_continuous(labels = comma) +
  labs(x = expression(CH[4]~flux~(nmol~m^-2~s^-1)), y = "Number of observations")
print(p)
ggsave("figures/figure7-ch4.png")
```


```{r sessionInfo}
# R session information
sessionInfo()
```
